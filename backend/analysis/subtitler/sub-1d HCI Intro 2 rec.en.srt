1 
00:00:0,000 --> 00:00:12,800 
 Last time, what did we discuss? The importance of HCI and that's doing less redesign. By 

2 
00:00:12,800 --> 00:00:22,240 
 that you have a huge cost reduction and avoiding disasters. That's also very important. We 

3 
00:00:22,240 --> 00:00:31,440 
 saw that computing started with doing batch jumps and we ended with social robots and what you 

4 
00:00:31,440 --> 00:00:39,680 
 can learn from that is that instead of just being an appendix to the machine, the machine should tend 

5 
00:00:39,680 --> 00:00:47,920 
 to the user's needs and that has made our work quite some more difficult because now we have to 

6 
00:00:47,920 --> 00:00:55,680 
 make machines that understand the user in a certain way. Now all the visionaries and the 

7 
00:00:56,480 --> 00:01:3,040 
 scruffy first prototypes that we have seen that's nothing to laugh at because these are the people 

8 
00:01:3,040 --> 00:01:10,720 
 what we call the trailblazers who pioneer the technology for us and they take home messages, 

9 
00:01:11,680 --> 00:01:16,480 
 know your use and context first before you start coding. 

10 
00:01:19,440 --> 00:01:23,040 
 So let's continue with the history of HCI. 

11 
00:01:25,600 --> 00:01:34,800 
 Here you see an example of scientists, technologists who envision in 1954 what a home 

12 
00:01:34,800 --> 00:01:40,240 
 computer would be like. We are looking at the Rand Corporation and as you can see, 

13 
00:01:42,400 --> 00:01:49,200 
 if your father was to buy this computer for you, you better clear out your bedroom because it's 

14 
00:01:49,200 --> 00:01:56,800 
 huge, it even looks like a ship in a certain way. What do these people say of Rand? 

15 
00:01:57,200 --> 00:02:6,240 
 Well, they have created this model to illustrate what a home computer could look like in the year 

16 
00:02:6,240 --> 00:02:15,360 
 2004 but they readily admit that the needed technology will not be economically feasible to 

17 
00:02:15,360 --> 00:02:22,400 
 the average home. Well they're right about that if you are building that kind of huge installations 

18 
00:02:22,480 --> 00:02:28,960 
 that we see in the picture. They also say that the computer will require not yet invented technology 

19 
00:02:28,960 --> 00:02:37,760 
 to actually work. That's also true but 50 years from now, we are talking 1954, scientific progress 

20 
00:02:37,760 --> 00:02:43,600 
 is expected to solve these problems and they were right about that. We were able to make things smaller 

21 
00:02:45,040 --> 00:02:50,240 
 with the teletype interface that's like the television screen that you see 

22 
00:02:50,800 --> 00:02:56,800 
 and the FORTRAN language, the computer will be easy to use. Now that's kind of funny because we 

23 
00:02:56,800 --> 00:03:3,360 
 now know that you cannot give users just a programming language, they will not know what to do with it 

24 
00:03:6,240 --> 00:03:14,480 
 but FORTRAN, I always say in class, take notice. That's one of those very old heritage languages 

25 
00:03:15,440 --> 00:03:22,000 
 and it's important because most of our financial transactions systems are still running on that 

26 
00:03:22,000 --> 00:03:32,000 
 so even if you do your AliPay app by the end of the day what the bank has to do is run FORTRAN 

27 
00:03:32,000 --> 00:03:38,640 
 language and the problem with software is that it can decay, it can go bad but there's nobody 

28 
00:03:39,600 --> 00:03:46,960 
 hardly anybody who can still program and restore and maintain such old heritage languages 

29 
00:03:46,960 --> 00:03:52,800 
 so it would be smart actually if you want to have some job security to start learning these old 

30 
00:03:52,800 --> 00:04:5,280 
 languages and help Hong Kong Island maintain its systems. A close-up of the stretch, you see that we 

31 
00:04:5,280 --> 00:04:12,960 
 are downsizing quite a bit, not the RAND Corporation personal computer because this is 

32 
00:04:12,960 --> 00:04:20,400 
 already a kind of a supercomputer for the time 1960s and that's because it has so many transistors 

33 
00:04:20,400 --> 00:04:31,280 
 inside. Quick overview, this is one of the circuit boards, it has 169 000 transistors, 

34 
00:04:32,080 --> 00:04:39,040 
 one of the funny things is that the temperature is regulated in an oil bath to keep the performance 

35 
00:04:39,040 --> 00:04:46,240 
 stable but it actually accepts the dedicated program languages but also something more general 

36 
00:04:46,240 --> 00:04:57,200 
 like FORTRAN. Some important developments happened between the 1960s and the 1980s. In the mid 60s 

37 
00:04:57,200 --> 00:05:3,760 
 it was still so that computers were too expensive for one single person and that's why they invented 

38 
00:05:4,320 --> 00:05:12,000 
 time-sharing systems that gave the illusion of being on one's own computer but you were actually 

39 
00:05:12,000 --> 00:05:21,520 
 all on one and the same mainframe with special workstations, terminals attached to it but it 

40 
00:05:22,480 --> 00:05:28,640 
 dramatically increased the accessibility of computers, more people joining in and that led 

41 
00:05:28,640 --> 00:05:36,480 
 to immediate need for human computer interaction because now you were dealing with interactive 

42 
00:05:36,480 --> 00:05:43,520 
 systems and languages and not just batch jumps feeding commands to a machine and there was a 

43 
00:05:43,520 --> 00:05:50,400 
 community that became a hole through communicating through the computers. 

44 
00:05:54,640 --> 00:06:2,320 
 One of those things is that ergonomics became important such as the ergonomics of the console, 

45 
00:06:3,600 --> 00:06:12,640 
 you get job control languages, the transistors are helping to make things smaller and by that it 

46 
00:06:12,720 --> 00:06:19,120 
 becomes more accessible for people to work with not just financially but also ergonomically. 

47 
00:06:20,640 --> 00:06:29,360 
 The interactive experience from the 60s to the 70s becomes an issue, you get interactive terminals, 

48 
00:06:29,360 --> 00:06:42,560 
 command shells, speech, synthesis and then we have in 1965 the first PC ever, it is the 

49 
00:06:42,560 --> 00:06:51,680 
 programa 101 by Olivetti and that's an Italian company, originally making typewriters and this 

50 
00:06:51,680 --> 00:06:57,680 
 model particularly looks a little bit like a calculator that a shop owner would have on the 

51 
00:06:57,680 --> 00:07:7,840 
 counter making up the bill for you so these older IDs are still visible in the newer developments 

52 
00:07:7,840 --> 00:07:18,720 
 such as this first PC ever and computers are getting cheaper because of all of this, something 

53 
00:07:18,720 --> 00:07:27,200 
 happens that is design rules that are made that are set up about personal computing, 

54 
00:07:27,200 --> 00:07:32,560 
 it's not that anything goes anymore, people get the kind of routine of how to deal with that, 

55 
00:07:32,560 --> 00:07:40,320 
 there are rules for dialogues, also in our assignments we will practice with those kind of 

56 
00:07:40,320 --> 00:07:48,880 
 rules and video text services started to become apparent, you see one of those on the right hand 

57 
00:07:48,880 --> 00:07:58,880 
 side the Minitel which is a video text system from France, now with all those rules happening 

58 
00:08:0,400 --> 00:08:8,160 
 there are now suddenly in the beginning end of the 60s these computing conferences it starts to 

59 
00:08:8,160 --> 00:08:16,080 
 become a science where they discuss document processing, hypermedia, input output devices, 

60 
00:08:16,080 --> 00:08:25,120 
 the mouse, the one-handed quarter keyboard, high resolution displays, they start talking about 

61 
00:08:25,120 --> 00:08:34,640 
 shared work so that's using context around the machine, how to share files, personal annotations, 

62 
00:08:34,640 --> 00:08:41,920 
 electronic messaging, audio video conferencing already 1968, now we are on zoom and on 

63 
00:08:42,960 --> 00:08:48,720 
 collaborate ultra and we find that all pretty normal, all IDs of an internet start to occur 

64 
00:08:49,360 --> 00:08:57,280 
 and user testing last but not least and user training so like driving a car you should know 

65 
00:08:57,280 --> 00:09:6,880 
 how to handle the machine apart from conferences HCI becomes a science with scientific journals 

66 
00:09:7,760 --> 00:09:13,280 
 and two of these that you see in the lower left of the slide international journal of human 

67 
00:09:13,280 --> 00:09:20,480 
 computer studies and ACM transactions on computer human interaction they are still Q1 highly ranked 

68 
00:09:20,480 --> 00:09:24,240 
 journals and fully established and matured 

69 
00:09:27,920 --> 00:09:36,560 
 also during the 1960s there are people who think beyond the current state of the art and are 

70 
00:09:37,440 --> 00:09:44,800 
 envisioning how computing will be in so many years time so Joseph Licklider is one of those 

71 
00:09:44,800 --> 00:09:53,040 
 visionaries and he tells us that the hope is that in not too many years human brains and 

72 
00:09:53,040 --> 00:09:59,440 
 computing machines will be coupled together very tightly and that the resulting partnership will 

73 
00:09:59,440 --> 00:10:5,200 
 think as no human brain has ever thought and process data in a way not approached by the 

74 
00:10:5,200 --> 00:10:12,240 
 information handling machines we know today and that he calls man computer symbiosis we would now 

75 
00:10:12,240 --> 00:10:18,160 
 say human computer symbiosis a famous paper by Joseph Licklider 

76 
00:10:20,720 --> 00:10:27,680 
 and in his wake many others start to think about that we have a book on human machine symbiosis 

77 
00:10:27,680 --> 00:10:40,160 
 from 1996 and then 2004 2005 Ray Kurzweil he's now owned by google is writing about the singularity 

78 
00:10:40,160 --> 00:10:46,240 
 which would be near what does he mean by that if you do a you should know the word singularity 

79 
00:10:46,240 --> 00:10:55,840 
 because it is the idea that at one point computing intelligence would be so great that it emulates 

80 
00:10:55,840 --> 00:11:3,280 
 human intelligence and then go beyond so it will be better one day that than humans can think and do 

81 
00:11:4,240 --> 00:11:14,160 
 now that's a quite big claim of course and there are some aspects to it that may be right and I 

82 
00:11:14,160 --> 00:11:20,080 
 will also tell you a little later about aspects to it that are not there yet 

83 
00:11:22,080 --> 00:11:29,040 
 but it is true that we have things like what Joseph Licklider said brain computer interfaces 

84 
00:11:29,040 --> 00:11:37,760 
 particularly people who are impaired in my example here they they are paralyzed 

85 
00:11:38,480 --> 00:11:47,120 
 they can control robotic arms using their brains so a signal is picked up played through 

86 
00:11:47,120 --> 00:11:55,600 
 the computer to the external arm the robotic arm and then the robotic arm will actually execute 

87 
00:11:55,600 --> 00:12:4,320 
 what the person is thinking so they are able to reach and to grasp objects that way in a 3d 

88 
00:12:4,320 --> 00:12:12,640 
 space using the robotic arm and they control it directly with their brain activity and you can 

89 
00:12:12,640 --> 00:12:20,000 
 even think about neuro gaming at the moment there are brain computer interfaces that they try to 

90 
00:12:20,000 --> 00:12:27,520 
 integrate with gaming so for instance where you look is where camera position will go or an action 

91 
00:12:27,520 --> 00:12:35,520 
 that you can execute while thinking of it and yeah we are in a way close to become cyborgs 

92 
00:12:35,520 --> 00:12:42,400 
 because we all have a granddaddy with a pacemaker or a grandmother with a cochlear implant for hearing 

93 
00:12:43,280 --> 00:12:51,600 
 or people who have artificial lenses imagine a person who has it all a pacemaker cochlear implant 

94 
00:12:51,600 --> 00:12:58,720 
 artificial lens an exoskeleton blades to walk on chips under the skin to check in at the bar 

95 
00:12:59,280 --> 00:13:6,480 
 metal joints knee and hips also has to go into the hospital for kidney dialysis or maybe when 

96 
00:13:6,480 --> 00:13:15,920 
 things are really going bad be kept alive in an intensive care unit that's very close to being a 

97 
00:13:15,920 --> 00:13:25,920 
 human computer symbiont now i was referring to the international journal of human computer studies 

98 
00:13:25,920 --> 00:13:33,120 
 i recently had a publication there which also includes the singularity and it actually says 

99 
00:13:33,120 --> 00:13:38,880 
 the singularity is far from near one of the problems being what do you mean about human 

100 
00:13:38,880 --> 00:13:46,000 
 intelligence or artificial intelligence well in the experiments that we did the we couldn't find a 

101 
00:13:46,000 --> 00:13:52,880 
 trace of it that people would experience something like that in state-of-the-art robotics if you 

102 
00:13:52,880 --> 00:13:58,000 
 want to have a look go ahead as you can see international journal of human computer studies 

103 
00:13:58,000 --> 00:14:9,040 
 is a life and kicking but back to joseph licklider who in a way uh was trailblazing was the forefront 

104 
00:14:9,040 --> 00:14:16,560 
 of all of this in that famous paper man computer symbiosis he writes down a couple of goals short 

105 
00:14:16,560 --> 00:14:23,440 
 term midterm and long term goals and it's quite remarkable how many of these things turned out 

106 
00:14:23,440 --> 00:14:31,760 
 to be an agenda for developing technology that we are using today because we do have that time 

107 
00:14:31,760 --> 00:14:38,160 
 sharing of computers among many users we don't do the time sharing anymore but we have sharing of 

108 
00:14:38,160 --> 00:14:45,680 
 computers and information among many users no no no problem with that electronic input output for 

109 
00:14:45,680 --> 00:14:52,400 
 display and communication of symbolic and pictorial information well everybody has symbolic and 

110 
00:14:52,480 --> 00:14:59,840 
 pictorial icons on their desktop or interactive real-time systems for information processing 

111 
00:14:59,840 --> 00:15:5,280 
 and programming yeah we do have that large-scale information storage and retrieval we have that 

112 
00:15:5,280 --> 00:15:15,040 
 too we have data farms we have big data retrieval analysis all of it intermediate goals the facilitation 

113 
00:15:15,040 --> 00:15:21,440 
 of human cooperation in the design and programming of large systems that we do many software houses 

114 
00:15:21,440 --> 00:15:28,560 
 have people abroad working together online do we have speeds recognition yes we do do we have 

115 
00:15:28,560 --> 00:15:36,080 
 hand printed character recognition yes we do do we have light pen editing well look at the upper 

116 
00:15:36,080 --> 00:15:44,560 
 right hand corner that's already 69 the hypertext editing system it's already there and also nowadays 

117 
00:15:44,560 --> 00:15:52,720 
 we have styluses on our tablets then the long-term visions natural language understanding well up to 

118 
00:15:52,720 --> 00:16:1,040 
 a certain extent we do have natural language processing we can do syntax and we can do semantics 

119 
00:16:1,040 --> 00:16:8,800 
 but what's still hard is pragmatics we don't know the role of the use of language yet 

120 
00:16:9,600 --> 00:16:15,040 
 can you say the sentence when you are in an informal setting in the bar can you say that 

121 
00:16:15,040 --> 00:16:22,640 
 same sentence also at the formal setting when you shake hands with the president you you will be 

122 
00:16:22,640 --> 00:16:29,280 
 different in the way you are talking and that's something we as scientists still don't really 

123 
00:16:29,280 --> 00:16:36,000 
 understand yet and therefore it's hard to teach to a computer so that's well one third of that 

124 
00:16:36,000 --> 00:16:43,680 
 point is still under development um speech recognition yeah we have of arbitrary computer 

125 
00:16:43,680 --> 00:16:50,400 
 users yeah still we can do that maybe not always perfect but it's there and heuristic programming 

126 
00:16:50,400 --> 00:16:57,520 
 yeah with all the fourth generation languages and for instance with graphical computing where you 

127 
00:16:58,640 --> 00:17:5,440 
 have two icons and you put an arrow in between that's heuristic programming you don't really 

128 
00:17:5,440 --> 00:17:16,160 
 have to know the language anymore now let me introduce to you ivan sutherland most people 

129 
00:17:16,160 --> 00:17:21,840 
 would consider him the least cool guy in the schoolyard because he looks like a bookkeeper 

130 
00:17:21,840 --> 00:17:30,000 
 with his big glasses um i think he's the most cool guy in the schoolyard and let me tell you why 

131 
00:17:30,000 --> 00:17:39,840 
 in 63 he develops the sketch pad and that's a drawing tool and what he does is he structures 

132 
00:17:39,840 --> 00:17:46,560 
 in a hierarchy particularly defined pictures and sub-pictures well we know that now right we 

133 
00:17:46,560 --> 00:17:52,960 
 are using icons aren't we and he does something that we now call object oriented programming 

134 
00:17:52,960 --> 00:17:58,240 
 i think that's pretty cool that's something we do now a master picture with instances 

135 
00:17:58,960 --> 00:18:5,600 
 those have constraints you can specify details which the system maintains through changes that's 

136 
00:18:5,600 --> 00:18:13,680 
 also new icons well we know i can small pictures that represent more complex items you can copy 

137 
00:18:13,680 --> 00:18:20,000 
 those both the pictures with the constraints and you have different input techniques with the 

138 
00:18:20,000 --> 00:18:26,960 
 efficient use of a light pan and all people with tablets and a stylus are indebted to ivan 

139 
00:18:28,240 --> 00:18:32,640 
 he actually develops the first graphical user interface the gooey 

140 
00:18:35,680 --> 00:18:44,000 
 so yeah apple makes soft user interaction the future i think ivan sutherland made soft 

141 
00:18:44,000 --> 00:18:50,560 
 user interaction the future so yeah steve jobs um ivan never heard of 

142 
00:18:50,560 --> 00:19:1,120 
 ivan sutherland he also goes into hardware in the following way he he helps to develop 

143 
00:19:1,120 --> 00:19:8,000 
 low-cost graphical terminals creates input devices such as data tablets which we still 

144 
00:19:8,000 --> 00:19:15,600 
 have data tablets and display processors capable of real-time manipulation of images 

145 
00:19:16,560 --> 00:19:25,760 
 and maybe even more impressive for us today he is the developer of 3d computer graphics 

146 
00:19:26,320 --> 00:19:36,240 
 and head mountain displays gamers pay tribute because those vr treadmills that we have nowadays 

147 
00:19:36,240 --> 00:19:43,120 
 they are directly indebted to the work of ivan sutherland you see that head mountain display 

148 
00:19:43,360 --> 00:19:49,840 
 it's almost like a helmet it needs to be kept up by that huge construction because otherwise 

149 
00:19:49,840 --> 00:20:0,640 
 just too heavy on your head but it's the first vr that we know and therefore ivan sutherland 

150 
00:20:0,640 --> 00:20:9,920 
 is your big granddaddy gamers most of you didn't even go into a vr treadmill but yeah they are there 

151 
00:20:10,800 --> 00:20:16,800 
 and they are the latest thing and you can show off to your other schoolmates but it's that old 

152 
00:20:16,800 --> 00:20:22,720 
 daddy that actually was making that possible how was it possible that an old daddy like that made 

153 
00:20:22,720 --> 00:20:30,320 
 that possible well because of the following this is his philosophy it seems to me that the most 

154 
00:20:30,320 --> 00:20:37,200 
 important thing that adults need to do with young people is not squash their curiosity 

155 
00:20:37,840 --> 00:20:45,760 
 but to help them exercise their curiosity and learn how to use it remember edison telling you 

156 
00:20:45,760 --> 00:20:54,320 
 make a lot of mistakes now remember ivan telling you be curious don't be put down don't let the rules 

157 
00:20:55,680 --> 00:21:1,920 
 restrain you in what you want to do because if rules are telling you what to do you won't do 

158 
00:21:1,920 --> 00:21:7,440 
 anything new you can be you cannot be curious you can only follow the template 

159 
00:21:10,560 --> 00:21:17,520 
 and he is another hero not following templates ellen k i'm sure nobody ever heard of him we are 

160 
00:21:17,520 --> 00:21:26,640 
 talking uh 1969 it's all about personal computing what he does is he developed a dyna book that's 

161 
00:21:26,720 --> 00:21:33,760 
 how he calls it and it's the vision of a notebook now even some of the current computers laptops are 

162 
00:21:33,760 --> 00:21:41,600 
 called notebooks what does he say imagine having your own self-contained knowledge manipulator 

163 
00:21:41,600 --> 00:21:49,040 
 well we all carry our self-contained knowledge manipulator we call it pc we call it tablet and 

164 
00:21:49,040 --> 00:21:56,000 
 we call it mobile phone in a portable package the size and shape of an ordinary notebook well 

165 
00:21:56,000 --> 00:22:2,640 
 that's exactly what we have suppose it had enough power to out raise your senses of sight and hearing 

166 
00:22:2,640 --> 00:22:11,520 
 well it does gpu far faster than me enough capacity to store for later retrieval thousands of page 

167 
00:22:11,520 --> 00:22:18,880 
 equivalents of reference materials well we all have that we have papers and pdfs and articles 

168 
00:22:18,880 --> 00:22:26,320 
 all on our machines poems letters yeah letters we do have letters emails recipes yeah people keep 

169 
00:22:26,320 --> 00:22:35,040 
 recipes on their knowledge manipulators records drawings yeah and not just artistic drawings 

170 
00:22:35,040 --> 00:22:42,480 
 but also technical drawings animations many people watch animations musical scores people listen 

171 
00:22:42,480 --> 00:22:52,240 
 to music on their machine and all of that came from cardboard prototyping nothing fancy no big 

172 
00:22:52,240 --> 00:23:1,120 
 prototypes on digital machines just trying out low level building it after the vision that you have 

173 
00:23:2,080 --> 00:23:6,800 
 he had tiles he had the stylus and then people can try out the good thing is 

174 
00:23:7,760 --> 00:23:15,040 
 less costly redesign if things don't work out the way you want a very good way to start developing 

175 
00:23:15,040 --> 00:23:21,200 
 new systems and we will do this too in our assignments you will do low level prototyping 

176 
00:23:21,200 --> 00:23:27,680 
 and just learn how it is to not digitally digitally understand the requirements of the user 

177 
00:23:27,920 --> 00:23:36,320 
 so yeah the apple macbook air is fully indebted to that idea of the 

178 
00:23:38,240 --> 00:23:46,160 
 dyna book that ellen k developed so also for ellen k steve jobs never heard of 

179 
00:23:49,120 --> 00:23:54,320 
 during that same period a little later in the 70s there's also something that comes 

180 
00:23:55,040 --> 00:24:4,240 
 from the more the the hackers kind of subculture there are people now such as ted nelson who see 

181 
00:24:4,240 --> 00:24:11,200 
 that all computing power is assembled by for instance ibm and only made available to other 

182 
00:24:11,200 --> 00:24:18,800 
 companies and they resist that what they want is that computing becomes operational accessible for 

183 
00:24:18,800 --> 00:24:27,360 
 all people that that's his computer liberation dream machine he wants deep computer literacy 

184 
00:24:27,360 --> 00:24:34,080 
 among all members of the community of society it's a kind of counterculture that we still 

185 
00:24:34,080 --> 00:24:42,640 
 see today like i said particularly the ethical hackers are a good example of the follow-up 

186 
00:24:42,640 --> 00:24:48,720 
 of what he wanted and against the centralization of computers such as ibm 

187 
00:24:53,120 --> 00:25:3,360 
 nevertheless the business type of computing just goes on no matter what this is the xerox park 1973 

188 
00:25:4,000 --> 00:25:9,920 
 and xerox may be a boring company because it's all about photocopy machines but they're not that 

189 
00:25:9,920 --> 00:25:16,960 
 boring because they are really going into personal computing with a graphical user interface and one 

190 
00:25:16,960 --> 00:25:24,560 
 of their first machines is the alto computer a personal workstation with a local processor bitmap 

191 
00:25:24,560 --> 00:25:32,240 
 displays and a mouse for that time very very modern they also have graphical interface with text 

192 
00:25:32,240 --> 00:25:40,640 
 drawing editing electronic mail like we now have email windows menus you see that that's that's not 

193 
00:25:40,640 --> 00:25:48,000 
 an invention by microsoft windows and menus and scroll bars mouse selection etc and the local 

194 
00:25:48,000 --> 00:25:56,320 
 area network the ethernet using the shared resources particular thing peculiar is that the 

195 
00:25:56,320 --> 00:26:1,200 
 disk screen display screen has a portrait orientation 

196 
00:26:4,160 --> 00:26:11,440 
 all right let's do a quiz item now you should raise your hand if you know who it is have you 

197 
00:26:11,440 --> 00:26:19,280 
 ever heard of ad mccrank he's a very famous man very important for computing but i'm afraid nobody 

198 
00:26:19,280 --> 00:26:28,080 
 heard of him what about chuck fecker chuck fecker you don't know this is butler lampson do you know 

199 
00:26:28,080 --> 00:26:33,440 
 who butler is but butler is very famous very important for particularly human computer interaction 

200 
00:26:33,440 --> 00:26:42,720 
 who's bop sprout you don't know or dav borgs still don't know well he's an important technician 

201 
00:26:42,720 --> 00:26:49,520 
 you know for the other things we do today on our computers uh steve jobs now all hands are raised 

202 
00:26:49,520 --> 00:26:58,240 
 right but steve wasniac people are not so sure about yeah what steve wasniac was the technologist 

203 
00:26:58,240 --> 00:27:5,920 
 let's say but then how come among all of these technologies that the only one who is the least 

204 
00:27:5,920 --> 00:27:13,120 
 technological is the most famous and then usually my students say quite righteously 

205 
00:27:13,120 --> 00:27:21,920 
 because he's great at marketing and so he was because look at this the xerox park that's the 

206 
00:27:23,440 --> 00:27:31,520 
 latest of xerox you will see that the ones who were actually making that computer are 

207 
00:27:32,160 --> 00:27:39,200 
 the computer after the alto is the result of a joint effort by ad mccrank which he didn't know 

208 
00:27:39,200 --> 00:27:45,280 
 chuck fecker but the lampson bop sprout and dav borgs and they were attempting to make a device 

209 
00:27:45,280 --> 00:27:52,080 
 that was small enough to fit in an office comfortably yet powerful enough to support a reliable high 

210 
00:27:52,080 --> 00:27:58,640 
 quality operating system and graphics display and this gooey featured in windows and icons 

211 
00:27:59,200 --> 00:28:5,200 
 and only a few years later so you know they didn't invent it they just went after it 

212 
00:28:5,840 --> 00:28:11,200 
 steve jobs and steve wasniac borrowed some of these ids and started apple computing 

213 
00:28:12,800 --> 00:28:18,400 
 and they borrowed from ellen k and from ivan sutherland and etc etc 

214 
00:28:18,400 --> 00:28:30,400 
 1980s the xerox star again personal computer but now commercialized it's a personal computer for 

215 
00:28:30,400 --> 00:28:37,680 
 business professionals you see just like ibm and against the computer liberation movement 

216 
00:28:38,320 --> 00:28:45,120 
 the first comprehensive graphical user interface using many ids developed earlier with the xerox 

217 
00:28:45,120 --> 00:28:53,440 
 park it now has a familiar conceptual model with a simulated desktop it promotes recognizing and 

218 
00:28:53,440 --> 00:29:1,440 
 pointing and not so much remembering and typing it has property sheets to specify the appearance of 

219 
00:29:1,440 --> 00:29:7,360 
 objects also the whole idea of what you see is what you get we think it's very modern but it's 

220 
00:29:7,360 --> 00:29:13,280 
 already there in the 80s with a small set of generic commands that could be used throughout 

221 
00:29:13,280 --> 00:29:19,600 
 the system with a high degree of consistency not too difficult a modulus interaction 

222 
00:29:20,640 --> 00:29:26,400 
 however with limited amount of used customization and this is one of the reasons why it didn't 

223 
00:29:26,400 --> 00:29:32,960 
 really fly this xerox star 8010 

224 
00:29:33,520 --> 00:29:43,680 
 but it is the first system based upon usability engineering it is an inspired design with 

225 
00:29:43,680 --> 00:29:51,920 
 extensive here we go again paper prototyping not technological prototyping and the analysis of 

226 
00:29:51,920 --> 00:29:58,720 
 use what do people do with it a lot of usability testing going on with potential users and an 

227 
00:29:58,800 --> 00:30:4,720 
 iterative refinement of the interface exactly like i told you before this is the way to go 

228 
00:30:5,760 --> 00:30:11,520 
 however and that's why it's so hard and that's why you need to analyze use not only use but 

229 
00:30:11,520 --> 00:30:20,880 
 also context it was a commercial failure because the cost uh 15 000 us would still be a quite a 

230 
00:30:20,880 --> 00:30:27,920 
 price for that kind of computer and unfortunately the competition ibm just announced a less 

231 
00:30:27,920 --> 00:30:34,160 
 expensive machine it was limited in its functionality it had for instance no spreadsheets 

232 
00:30:34,720 --> 00:30:42,080 
 and that was not too smart a closed architecture so you could not use any other software on it 

233 
00:30:42,080 --> 00:30:50,720 
 than the xerox allowed you it was perceived as slow but actually really fast in other words 

234 
00:30:51,280 --> 00:30:58,480 
 be aware that you may overclock your gpu but that people don't necessarily feel it that way 

235 
00:30:58,480 --> 00:31:5,600 
 this is why you do user experience research it may on the clock be faster or slower but it's not 

236 
00:31:5,600 --> 00:31:14,400 
 necessarily that people will perceive it that way and the xerox star was too strongly adhering to 

237 
00:31:14,400 --> 00:31:21,520 
 direct manipulation so you could not if you wanted pop up the c prompt and type in something 

238 
00:31:21,520 --> 00:31:32,320 
 of a command the 1980s the user becomes more and more important and is approached more naturally 

239 
00:31:32,320 --> 00:31:38,000 
 there are systemic principles to deal with users and how users would deal with their computers 

240 
00:31:38,000 --> 00:31:45,200 
 there's a human protocol now windows and graphical interfaces are more or less becoming standard 

241 
00:31:46,080 --> 00:31:54,480 
 PCs gain in power and they can store data or mainframes they have graphics and already speech 

242 
00:31:54,480 --> 00:32:3,280 
 processing one of the commercial machines during that period coming out is the apple lisa and it's 

243 
00:32:3,280 --> 00:32:11,280 
 based upon many ideas of the xerox star the predecessor of the macintosh that we now know 

244 
00:32:11,280 --> 00:32:19,120 
 and it's somewhat cheaper ten thousand dollars still quite a price however still a commercial failure 

245 
00:32:19,120 --> 00:32:28,880 
 so as you can see although it is building upon developments created by others already knowing 

246 
00:32:29,440 --> 00:32:36,320 
 that you shouldn't overprice it's still a kind of fine tuning that apple has to do because before 

247 
00:32:36,320 --> 00:32:48,720 
 they become a success and they become a success in 1984 the apple macintosh personally that's also 

248 
00:32:48,720 --> 00:32:58,560 
 my first acquaintance with apple and why is it a success because many others invented what then is 

249 
00:32:58,640 --> 00:33:6,720 
 old ideas but now they can improve them and do them real well and they also succeed not just because 

250 
00:33:6,720 --> 00:33:12,800 
 of technology but here we go again with the context they have a very sharp pricing it's a relatively 

251 
00:33:12,800 --> 00:33:20,240 
 cheap twenty five hundred dollars and it didn't have to do all the pioneering the trailblazing 

252 
00:33:20,240 --> 00:33:25,840 
 being in the forefront because that's costly right they were just waiting for the time to be 

253 
00:33:25,840 --> 00:33:34,640 
 ripe and they corrected the mistakes of their earlier lisa now they have mature ideas the market 

254 
00:33:34,640 --> 00:33:43,840 
 is ready so if you want to upload your newest your latest game to google play be sure that people 

255 
00:33:43,840 --> 00:33:51,040 
 actually wanted that they are ready to pay for it otherwise it will just sit there also smart 

256 
00:33:51,040 --> 00:33:58,240 
 they had a developers toolkit by which you could use those third-party softwares that were non-apple 

257 
00:33:59,120 --> 00:34:5,120 
 they had interface guidelines uh they wanted consistency between applications that's what 

258 
00:34:5,120 --> 00:34:14,400 
 they still do and also very good they developed an infrastructure around the machine they developed 

259 
00:34:14,400 --> 00:34:24,320 
 they were dominant in desktop publishing because they also could deliver a affordable laser printer 

260 
00:34:24,320 --> 00:34:30,800 
 that was the latest hottest thing at that time with excellent graphics and still apple is the 

261 
00:34:30,800 --> 00:34:40,720 
 preferred operating system machine to work on if you want to do graphics however in spite of all of 

262 
00:34:40,720 --> 00:34:49,120 
 this they have a strange thing in their interfaces particularly in the older ones such as this apple 

263 
00:34:49,120 --> 00:34:56,640 
 macintosh people if they want to store something they want to keep you put it on a disk in those 

264 
00:34:56,640 --> 00:35:3,760 
 times it was called a floppy disk but then if you want to eject the floppy disk you have to trash it 

265 
00:35:4,400 --> 00:35:12,160 
 now that's not very smart because trash and a bin are not related to something you want to keep 

266 
00:35:12,160 --> 00:35:20,000 
 so from an association semantic point of view it's not really smart to have people throw things 

267 
00:35:20,000 --> 00:35:27,280 
 away in order to get them out of your machine and also in the more modern versions that I 

268 
00:35:27,280 --> 00:35:34,560 
 showed you on the right hand side you still need to pull the external drive to the trash can 

269 
00:35:35,440 --> 00:35:41,760 
 but then luckily it changes it to another icon for ejection but it still has has that counter 

270 
00:35:41,760 --> 00:35:55,760 
 intuitive feeling of trashing to eject from the 1980s on until now the user takes center stage 

271 
00:35:55,760 --> 00:36:3,680 
 all of your applications have to deal with how users are going about we have integrated 

272 
00:36:3,680 --> 00:36:9,200 
 multimodal systems you can handle the same app from your telephone as you can from your pc 

273 
00:36:10,000 --> 00:36:16,000 
 there is something called ubiquitous computing word you should know all computing systems out 

274 
00:36:16,000 --> 00:36:20,960 
 of your face you don't need to sit behind the screen type something in but it's in your house a 

275 
00:36:20,960 --> 00:36:28,800 
 smart home the internet of things we interact with it without directly typing in or clicking something 

276 
00:36:30,080 --> 00:36:36,160 
 some systems try to detect your emotions in order to adapt to it also in gaming you will find that 

277 
00:36:36,160 --> 00:36:40,800 
 one of the ways to do that for instance you see on the right hand side is that they measure 

278 
00:36:41,360 --> 00:36:50,240 
 physiological data for instance heat so a red forehead would indicate surprise or a cold 

279 
00:36:50,320 --> 00:36:59,040 
 face would indicate fear but be very careful with that that a hot forehead may also be because i'm 

280 
00:36:59,600 --> 00:37:6,480 
 stressed or i feel love and a cold face may also be because the heating is not on 

281 
00:37:6,480 --> 00:37:16,720 
 so important lesson emotion expression doesn't mean that i feel the emotion i can also play being angry 

282 
00:37:21,200 --> 00:37:28,480 
 all right lessons learned from the history of hchi in the old days computers would cost more than 

283 
00:37:28,480 --> 00:37:37,120 
 people do today people cost far more than computers do and applications can now afford to trade off 

284 
00:37:37,120 --> 00:37:45,840 
 processing power for human usability it doesn't have to be faster and even correct um because 

285 
00:37:45,920 --> 00:37:54,080 
 humans don't even perceive that anymore new ideas often don't make it into products straight away 

286 
00:37:54,080 --> 00:38:1,520 
 there is a long time of development before something becomes market ready the pioneer systems 

287 
00:38:2,080 --> 00:38:9,280 
 they develop the innovative designs like ellen k for instance or ivan sutherland but often they 

288 
00:38:9,280 --> 00:38:17,280 
 are commercially not viable yet see the xerox park settlers systems so they are after the 

289 
00:38:17,280 --> 00:38:24,800 
 pioneers they settle down they incorporate very often all of these older ideas many years later 

290 
00:38:24,800 --> 00:38:34,560 
 but then well researched they did a lot of hchi work with users iterations prototyping make designs 

291 
00:38:34,560 --> 00:38:43,280 
 that now are evaluated as good better than before and so they are ready to market 

292 
00:38:48,000 --> 00:39:0,000 
 so what is hchi today it's not just computing it's also computing but it's also hardcore computer 

293 
00:39:0,000 --> 00:39:7,440 
 science it is also artificial intelligence you will need to deal with people who can engineer 

294 
00:39:7,440 --> 00:39:13,120 
 you will encounter cognitive psychologists you will have to deal with people who know about 

295 
00:39:13,120 --> 00:39:20,000 
 ergonomics or in other words human factors sociologists people who know about communication 

296 
00:39:20,560 --> 00:39:25,600 
 anthropology linguistics industrial design you name it it's all there 

297 
00:39:25,600 --> 00:39:35,680 
 an example from computer science very close to the hardware you may or may not know that the 

298 
00:39:35,680 --> 00:39:43,680 
 united states have a problem with people who want who want to cross the border from mexico to texas 

299 
00:39:44,880 --> 00:39:51,760 
 and the u.s department of homeland security they want driver's licenses with an rfid tag 

300 
00:39:51,760 --> 00:39:57,360 
 that you can read from a distance to use for patrol of the u.s mexican border 

301 
00:39:59,120 --> 00:40:11,280 
 however such a rfid tag may be reprogrammed with a virus here comes the virus and that was tried 

302 
00:40:11,280 --> 00:40:19,760 
 out here we have the ethical hacker culture but one of my former colleagues in the v u 

303 
00:40:19,760 --> 00:40:29,120 
 university of amsterdam melanie rebach and she invented the first rfid virus so by that she 

304 
00:40:29,120 --> 00:40:36,800 
 showed that this kind of identification is a kind of dangerous but she also comes up with a solution 

305 
00:40:36,800 --> 00:40:44,000 
 so computer science is the programming of the virus but now the engineering is that she comes 

306 
00:40:44,000 --> 00:40:51,520 
 up with something different than just computing she comes up with a circuit board with two antenna 

307 
00:40:52,240 --> 00:40:59,600 
 and onboard processors and that intercepts the signals from the rfid readers and like a software 

308 
00:40:59,600 --> 00:41:7,680 
 firewall it now doesn't let those signals reach the rfid unless you want them to for example if 

309 
00:41:7,680 --> 00:41:15,840 
 you're passing through customs so by that it's far harder to put viruses on that rfid and user is in 

310 
00:41:15,840 --> 00:41:26,880 
 control or what about this artificial intelligence many of these self-driving cars have a problem 

311 
00:41:27,520 --> 00:41:35,600 
 kill people because it decides not to swerve so not to go around it and the cars sensors saw the 

312 
00:41:35,600 --> 00:41:42,720 
 woman but may have flagged the detection as a false positive what you learn from that is that 

313 
00:41:42,720 --> 00:41:48,480 
 artificial intelligence has a direct effect on usability and particularly on the on the 

314 
00:41:49,200 --> 00:41:55,440 
 other stakeholders in the car such as people on the road who are killed by that machine 

315 
00:41:56,800 --> 00:42:3,840 
 and that's because the ai is not good enough you cannot just test in perfect circumstances 

316 
00:42:3,840 --> 00:42:12,240 
 the ai cannot handle these exceptions why is that because exceptions are not in the training set 

317 
00:42:12,240 --> 00:42:21,280 
 or they are getting very low weights so what it can do is handle all the known patterns what it 

318 
00:42:21,280 --> 00:42:27,840 
 can hardly do is handle the unknown patterns and this is exactly what humans do better than any 

319 
00:42:27,840 --> 00:42:36,720 
 computing system they do one trial learning that's one one aspect the other is even situations they 

320 
00:42:36,720 --> 00:42:46,320 
 have never ever encountered before they can handle and that's really something different from what any 

321 
00:42:47,040 --> 00:42:48,000 
 ai may do 

322 
00:42:48,880 --> 00:42:56,400 
 yeah you will also encounter the Douglas Engelbart of this planet the engineers who was augmenting 

323 
00:42:56,400 --> 00:43:1,840 
 human intellect with a conceptual framework well it wasn't that conceptual it was actually this 

324 
00:43:1,840 --> 00:43:9,920 
 little mouse uh with a you know with a little box that was falling apart almost and two wheels 

325 
00:43:9,920 --> 00:43:16,000 
 going left and right and up and down um that's the type of person you also need to do that 

326 
00:43:16,160 --> 00:43:21,200 
 that's the type of person you also need to deal with because you need now to code 

327 
00:43:21,200 --> 00:43:24,400 
 something completely different from a keyboard 

328 
00:43:27,040 --> 00:43:34,800 
 and yeah nowadays we all find that normal the logitech revolution mouse but the revolution was 

329 
00:43:34,800 --> 00:43:39,680 
 actually in what Douglas Engelbart did that that scruffy little wooden box 

330 
00:43:39,680 --> 00:43:50,880 
 cognitive psychologist why is your computing directly related a one-to-one link to psychology 

331 
00:43:50,880 --> 00:43:58,720 
 well this thing that you should program for remembering me or a module for for getting 

332 
00:43:58,720 --> 00:44:6,720 
 passwords or for getting an account name the people who study memory and recognizing and 

333 
00:44:6,720 --> 00:44:13,360 
 forgetting those are the psychologists so you are programming that because people have that kind of 

334 
00:44:13,360 --> 00:44:21,520 
 psychological issues let's say memory overloads courses security issues because passwords are too 

335 
00:44:21,520 --> 00:44:28,640 
 simple and now you have to make something that you know warns the people that the password is too 

336 
00:44:28,640 --> 00:44:35,440 
 simple sometimes they are related to the user self they repeat the same password everywhere 

337 
00:44:35,440 --> 00:44:41,840 
 you need to know all of these things to make something to uh accommodate that kind of behavior 

338 
00:44:41,840 --> 00:44:49,440 
 or they forget passwords so your programming routines they make up for user error and that's 

339 
00:44:49,440 --> 00:44:56,400 
 the direct link between requirements on the system the human side and what you will code what you 

340 
00:44:56,400 --> 00:45:8,560 
 will program on the backhand ergonomics or in american english human factors that's more on 

341 
00:45:8,560 --> 00:45:16,800 
 the physical input output side this kind of pens for instance to avoid repetitive strain injury 

342 
00:45:17,520 --> 00:45:23,360 
 you also see these single-handed ergonomic keyboards there have been many experiments 

343 
00:45:23,440 --> 00:45:30,160 
 with different layouts in keyboards and different forms of keyboard it never really flew but you 

344 
00:45:30,160 --> 00:45:38,640 
 can see they tried to change the ergonomics so that the hands would be spared not strained too much 

345 
00:45:39,440 --> 00:45:49,440 
 you can also think of the ergonomics of a vr system when you get like motion sickness or in this 

346 
00:45:49,440 --> 00:45:58,000 
 case the gate recognition suit all of that is either limiting you or it gives you possibilities 

347 
00:45:58,000 --> 00:46:6,160 
 you didn't have before that's ergonomics what about sociologists why why would you know about that 

348 
00:46:6,160 --> 00:46:16,960 
 well think of social media and how people make posts or make their moments on we chat and that's 

349 
00:46:17,040 --> 00:46:26,320 
 not just for diary purposes it's also to establish social groups to show your affiliation to show 

350 
00:46:26,320 --> 00:46:33,440 
 that you're a particular type of person going to these exhibitions or that cool festival or that 

351 
00:46:33,440 --> 00:46:43,760 
 you know this important provost of the university all of that is sociological behavior and you 

352 
00:46:43,760 --> 00:46:54,720 
 want to know how social networks are functioning in order to have your new social media app make 

353 
00:46:54,720 --> 00:47:5,200 
 any chance in communication there's something a special section called computer mediated 

354 
00:47:5,200 --> 00:47:11,760 
 communication because these people found out that not every medium is fit for every purpose 

355 
00:47:12,080 --> 00:47:20,800 
 why do we nowadays do face-to-face teaching again because for the task of teaching that seems to 

356 
00:47:20,800 --> 00:47:26,640 
 be better than me emailing you with the same content you know same information but I just put 

357 
00:47:26,640 --> 00:47:35,840 
 it on the email or that we would have a social media app and app around the questions and the 

358 
00:47:36,480 --> 00:47:46,160 
 remarks and I do the teaching on this that's not really fit however there are also situations where 

359 
00:47:46,160 --> 00:47:54,320 
 social media would be preferred over face-to-face or where you would write an email for instance you 

360 
00:47:54,320 --> 00:48:1,680 
 may be very angry and you want your money back from the company but face-to-face you flare up too much 

361 
00:48:2,480 --> 00:48:9,520 
 so by emailing you have time to think to rephrase and then you send and you don't say I am mad at 

362 
00:48:9,520 --> 00:48:19,840 
 you but I'm highly surprised I've also seen particularly boys breaking up with their girlfriend 

363 
00:48:19,840 --> 00:48:28,320 
 through an app I don't love you anymore sorry yeah what's that you know hiding behind the media 

364 
00:48:28,320 --> 00:48:34,000 
 that's what people do because in a face-to-face confrontation then you need to explain and 

365 
00:48:34,000 --> 00:48:40,480 
 the girl starts crying and you have an hour of talking and why yes and why no and who did what 

366 
00:48:40,480 --> 00:48:45,760 
 and everybody blaming everybody else and it takes another hour and a third hour of crying 

367 
00:48:45,760 --> 00:48:50,880 
 and that's really far harder than just saying I don't love you anymore sorry 

368 
00:48:51,760 --> 00:49:0,320 
 anthropology what's that well that's actually the study of humans in a culture and that could be 

369 
00:49:0,320 --> 00:49:6,560 
 international culture like people from China versus how do people in Japan deal with mobile 

370 
00:49:6,560 --> 00:49:13,760 
 phones or people in Europe but it's also occupational culture so culture on the work 

371 
00:49:13,760 --> 00:49:21,600 
 floor the the culture of Xerox will be different from IBM or different from Google and all of 

372 
00:49:21,600 --> 00:49:30,000 
 that weighs in that's used in context on how people deal with your systems example the Nokia 

373 
00:49:30,000 --> 00:49:39,920 
 that that was the iPhone of well let's say the early 2000s one of their new features was calling 

374 
00:49:39,920 --> 00:49:46,400 
 line identification and in western countries that was really nice because now you could see that the 

375 
00:49:46,400 --> 00:49:55,360 
 bird was calling you but in non-western cultures that didn't fly particularly not in India why 

376 
00:49:55,360 --> 00:50:6,480 
 didn't it work in India well because in India you have this caste system very strong hierarchy and 

377 
00:50:6,560 --> 00:50:14,960 
 it is a matter of respect that when your boss is calling you that you will recognize his voice 

378 
00:50:14,960 --> 00:50:22,240 
 and then say hello boss so nice that you are calling me but now because of this identification 

379 
00:50:22,240 --> 00:50:30,160 
 of the caller you can immediately see the name in the interface and you can say hey Sanjay are you 

380 
00:50:30,880 --> 00:50:40,400 
 there so that was really like a misfit of the feature that somebody programmed and 

381 
00:50:41,120 --> 00:50:46,240 
 that went to market and did well in western cultures but was really not good in India 

382 
00:50:47,360 --> 00:50:56,480 
 this is anthropology the study of how people deal in different cultures with your interactive systems 

383 
00:50:56,720 --> 00:51:10,160 
 he is an other example of anthropology culture and interactive systems now people with a 

384 
00:51:10,160 --> 00:51:17,440 
 muslim background they know what the burqa is a burqa is a long cloth like you see here in blue 

385 
00:51:18,400 --> 00:51:26,000 
 covering all including the face of a woman's body that's a requirement from the religion 

386 
00:51:26,000 --> 00:51:33,840 
 women should not be visible for whatever reason however in the west they thought of well that's 

387 
00:51:33,840 --> 00:51:39,760 
 something now we have somebody showing the burqa on the catwalk but we cannot see who's underneath 

388 
00:51:39,760 --> 00:51:47,200 
 so they integrated some bluetooth technology into the burqa and then you could through your mobile 

389 
00:51:47,200 --> 00:51:55,680 
 phone see who was under the burqa by which the very function of the burqa in orthodox 

390 
00:51:55,680 --> 00:52:5,360 
 muslim culture is annihilated so that was kind of insulting for that kind of people with that religion 

391 
00:52:6,720 --> 00:52:14,880 
 because it's exactly that you should not know who is underneath and not look at the woman with her 

392 
00:52:15,760 --> 00:52:20,720 
 hair hanging down and you know the neck being visible 

393 
00:52:20,720 --> 00:52:33,600 
 linguistics nowadays with large language models like gpt that's pretty obvious and we have siri 

394 
00:52:33,600 --> 00:52:41,600 
 and alexa google assistant cortana that's all operated through the voice but something interesting 

395 
00:52:41,600 --> 00:52:48,160 
 that linguists will tell you is why it is so that it's easier to go from text to speech 

396 
00:52:48,880 --> 00:52:59,040 
 than it is from speech to text text is an abstraction from speech everybody speaks 

397 
00:52:59,040 --> 00:53:9,200 
 differently it's not just that we have accents we also have our individual accents idiosyncrasies 

398 
00:53:9,200 --> 00:53:17,200 
 they call that and the letter r spoken by one person differs a little bit spoken by somebody 

399 
00:53:17,200 --> 00:53:24,080 
 else the third person the fourth person etc so it's far harder there's far more variability for a 

400 
00:53:24,080 --> 00:53:32,400 
 computer to recognize an r but in text that r is the same for everybody so it's easy to 

401 
00:53:32,400 --> 00:53:41,600 
 generate the sound from a text because it goes from very strict text to ever a more variability 

402 
00:53:42,160 --> 00:53:48,480 
 whatever voice you use for it but the other way around is hard many different options 

403 
00:53:48,480 --> 00:53:57,600 
 that should be pinned down to only one the r or the p or the t so this is why it's so that it's 

404 
00:53:57,600 --> 00:54:5,280 
 harder to go from speech to text than from text to speech and knowing that information 

405 
00:54:5,520 --> 00:54:14,000 
 that's why you need linguistics may help you define the next generation of speech to text 

406 
00:54:15,760 --> 00:54:16,400 
 applications 

407 
00:54:19,920 --> 00:54:25,520 
 and then industrial design pretty obvious i mean why would anyone buy a macintosh 

408 
00:54:26,240 --> 00:54:33,920 
 they love the apple iphone because of its design just how it looks but also these kind of 

409 
00:54:34,880 --> 00:54:40,880 
 keyboards that are resistant to water alcohol or you can roll them up put them in your back 

410 
00:54:41,680 --> 00:54:48,000 
 all of this or they light up in the dark all of this will have an effect on what you can code and 

411 
00:54:48,000 --> 00:54:54,560 
 what you cannot because a corded keyboard takes other technology than a wi-fi keyboard for instance 

412 
00:54:55,120 --> 00:55:8,000 
 so yeah you will practice with understanding users through experiments 

413 
00:55:9,600 --> 00:55:16,400 
 we will do task centered system design you will develop task examples and evaluate your 

414 
00:55:16,400 --> 00:55:23,520 
 designs through a task centered walk through so you go together with the user through the 

415 
00:55:23,520 --> 00:55:33,360 
 different stages of the system asking them how does it feel did you understand you will have 

416 
00:55:33,360 --> 00:55:42,640 
 a webcam to see how they move how they do you will also for instance if you do use a technical 

417 
00:55:42,640 --> 00:55:50,240 
 device you can do the click logs other user measurements and you will design with the user 

418 
00:55:51,200 --> 00:55:57,280 
 that's user centered design and prototyping you will have methods for designing with the user 

419 
00:55:57,840 --> 00:56:5,680 
 and most importantly the best is to use low and medium fidelity prototyping so like i said you 

420 
00:56:5,680 --> 00:56:14,640 
 can have a paper mockup or a paper prototype and at best maybe put it into a powerpoint and people 

421 
00:56:14,640 --> 00:56:22,960 
 can click through the slides you will learn more in the remainder of this course about the role of 

422 
00:56:22,960 --> 00:56:31,040 
 evaluation in design how to do user tests and how to observe people using systems and detect 

423 
00:56:31,040 --> 00:56:41,360 
 interface problems in designing interactive systems you should ask yourself what makes a 

424 
00:56:41,360 --> 00:56:51,680 
 visual design work it's the placement of interface components on the screen that's for one and i've 

425 
00:56:51,680 --> 00:56:58,640 
 seen websites where you have to scroll through five pages before you can click the okay so just 

426 
00:56:58,640 --> 00:57:6,320 
 that okay button is not visible you have to look for it but it's also about representations and 

427 
00:57:6,320 --> 00:57:16,080 
 metaphors what are metaphors well look in the lower left corner the home button there's no house 

428 
00:57:16,080 --> 00:57:23,120 
 involved there's no home there some people would even say yeah but that that's the starting menu 

429 
00:57:23,680 --> 00:57:30,320 
 yeah but menu also has nothing to do with food in this case those are metaphors like we have 

430 
00:57:30,320 --> 00:57:40,640 
 metaphors for trashing the trash can the bin or maybe a magnifying glass to search but it's a 

431 
00:57:40,640 --> 00:57:50,880 
 digital search you don't hold a magnifying glass so metaphors are you use an item from one category 

432 
00:57:51,520 --> 00:57:58,320 
 in order to represent an item from another category so home comes from architecture 

433 
00:57:59,040 --> 00:58:7,360 
 but you use it to represent an aspect of a digital interface that's metaphor and you will see if you 

434 
00:58:7,360 --> 00:58:15,840 
 go through your own interfaces how many metaphors we stack one upon the other there is also principles 

435 
00:58:15,840 --> 00:58:24,800 
 of design we even have one well law of design which is fits law if you look into the little 

436 
00:58:24,800 --> 00:58:31,280 
 algorithm you don't need to know the algorithm by heart if we are gonna use that on the exam i 

437 
00:58:31,280 --> 00:58:37,280 
 will give you the algorithm show you what everything means and then you can eventually calculate with 

438 
00:58:37,280 --> 00:58:47,920 
 it basically comes down to this an interface item can be large or small smaller is harder than larger 

439 
00:58:48,720 --> 00:58:53,760 
 it can be close by to click it and it can be further away to click it 

440 
00:58:55,200 --> 00:59:4,720 
 further away is harder than close by so if you have a mouse that should click the small button 

441 
00:59:4,720 --> 00:59:12,480 
 or click the large button it's pretty simple to say what should be because you know that 

442 
00:59:13,440 --> 00:59:21,760 
 large is simpler than small however if you only have the screen real estate of a phone 

443 
00:59:22,640 --> 00:59:28,640 
 you can make things bigger but then you can only place two items on it so where's the optimum 

444 
00:59:29,280 --> 00:59:37,840 
 what in these ambiguous cases that you have a smaller item far away or no a smaller item close by 

445 
00:59:38,640 --> 00:59:46,640 
 or a larger item further away well then that's what you need then is what you what you should do 

446 
00:59:46,640 --> 00:59:55,200 
 is calculate fits law so it can show you if i go with my mouse to the large item or from the 

447 
00:59:55,200 --> 01:00:1,680 
 large item back to the small item how correct and how fast are we in doing that 

448 
01:00:2,400 --> 01:00:8,160 
 and this is one metaphor for you the home button 

449 
01:00:10,640 --> 01:00:18,880 
 all right all in all humans are good at sensing of low level stimuli so if you are designing 

450 
01:00:18,880 --> 01:00:26,960 
 for humans you can have let them do that they are far better at pattern recognition than any AI 

451 
01:00:26,960 --> 01:00:35,200 
 system is they can do inductive reasoning so they need a few signals in order to understand 

452 
01:00:35,200 --> 01:00:40,560 
 already what the course will be they can handle multiple strategies at the same time they are 

453 
01:00:40,560 --> 01:00:48,320 
 very adaptive and they can create computers are best at counting measuring so let them do that 

454 
01:00:48,880 --> 01:00:55,600 
 they can accurately store and recall data very fast consistent in their responses 

455 
01:00:56,160 --> 01:01:2,880 
 they can do data processing usually better than humans do calculate and do a lot of repetitive 

456 
01:01:2,880 --> 01:01:10,000 
 actions without getting bored however currently we also make computers that are moving up the rank 

457 
01:01:10,000 --> 01:01:15,600 
 so they are doing pattern recognition there is something called artificial creativity that we 

458 
01:01:15,600 --> 01:01:22,800 
 now have and up to a certain extent it can do what humans do but like i said there's a limit 

459 
01:01:22,800 --> 01:01:29,360 
 to it so be careful not to overshoot your goal by thinking your AI can do things that humans 

460 
01:01:30,080 --> 01:01:33,360 
 don't need to do anymore that's not true they should collaborate 

461 
01:01:37,200 --> 01:01:42,080 
 so in this course here's the summary for you we have taught and we are teaching 

462 
01:01:43,040 --> 01:01:49,600 
 why HCI is crucial in system design and how to make sure that users become an integral part of 

463 
01:01:49,600 --> 01:01:56,400 
 your thinking it's not just coding language it's not just shall I do python or C sharp 

464 
01:01:58,080 --> 01:02:4,400 
 human computer interaction is not only important to create nice user experience it's also to avoid 

465 
01:02:4,400 --> 01:02:12,240 
 costly redesign to sell more products or services and we have seen shocking examples where bed design 

466 
01:02:12,240 --> 01:02:19,440 
 caused human disaster with nuclear power plants or with airlines airplanes 

467 
01:02:21,200 --> 01:02:29,200 
 now by definition HCI is concerned with design with implementation and with evaluation of interactive 

468 
01:02:29,200 --> 01:02:36,960 
 computing systems for human use and it provides input language for the user output language for 

469 
01:02:36,960 --> 01:02:46,800 
 the machine and a protocol for both to interact in the historical context that we saw the focus 

470 
01:02:46,800 --> 01:02:53,840 
 is shifting away from humans servicing computers which in a way is simple for us programmers 

471 
01:02:53,840 --> 01:02:58,720 
 because it's only the computer you need to deal with the humans will adapt to it 

472 
01:02:58,720 --> 01:03:4,480 
 but nowadays we must make systems that can serve as humans so now the system must be 

473 
01:03:4,480 --> 01:03:10,960 
 more adaptive and that's very hard to do therefore you should work with many disciplines that can 

474 
01:03:10,960 --> 01:03:19,760 
 collaborate because you don't know everything that is to be known a computer system should fit 

475 
01:03:19,760 --> 01:03:25,680 
 human use therefore go into computer science social science mathematics psychology physics 

476 
01:03:25,680 --> 01:03:33,120 
 you name it all of that is needed for interaction design if you don't do a poor HCI design makes 

477 
01:03:33,200 --> 01:03:37,920 
 even you as the toughest computer on earth look stupid 

478 
01:03:43,200 --> 01:03:51,440 
 okay let's practice with an item on your exam something you may expect we have three 

479 
01:03:51,440 --> 01:03:59,760 
 different types of questions one is knowledge so you just remember what fits law is about right 

480 
01:04:0,720 --> 01:04:8,240 
 or you have an application that's applying something you learn to for instance the 

481 
01:04:9,120 --> 01:04:14,400 
 example of the fat finger syndrome you remember with the stock market in japan 

482 
01:04:15,440 --> 01:04:22,640 
 or you get a inside question now you have to relate two knowledge items to one another such in this 

483 
01:04:22,640 --> 01:04:31,600 
 case how is fits law related to the fat finger syndrome then you get a number of answering 

484 
01:04:31,600 --> 01:04:38,000 
 categories and usually one of them is total nonsense and the others are pretty okay but 

485 
01:04:38,000 --> 01:04:45,120 
 there's only one really correct and most complete and you always go for the most correct and the 

486 
01:04:45,120 --> 01:04:55,680 
 most complete answer answer one a stress worsens performance or b fits reckons with the width 

487 
01:04:55,680 --> 01:05:3,520 
 ratio between pointer and interface widget or the logarithmic distribution for fat fingers 

488 
01:05:3,520 --> 01:05:12,800 
 differs from for instance mouse pointers or a and b are both correct so now it's for you to think 

489 
01:05:13,520 --> 01:05:19,280 
 you must know what fits law is you should know what the fat finger syndrome was about and then 

490 
01:05:19,280 --> 01:05:31,760 
 relate the answers to that question so here we go it's a and b that are correct why do i say 

491 
01:05:31,760 --> 01:05:40,880 
 well let's first look into fits law it was that the wider an interface which it is and the closer 

492 
01:05:41,360 --> 01:05:50,320 
 it is to the pointer then the easier it is to hit it and particularly when the pointer is wide as 

493 
01:05:50,320 --> 01:06:0,080 
 well the fat finger yeah so in the stock market that man made a big mistake he had big fingers 

494 
01:06:0,080 --> 01:06:7,280 
 and he was pointing to a small thing in the interface hitting another button as well and now 

495 
01:06:7,280 --> 01:06:14,480 
 he sells at the wrong price and the whole tokyo stock market suffers from it so in this case 

496 
01:06:14,480 --> 01:06:22,880 
 it's easy to hit with a big finger something small it's about the pointer to target width ratio 

497 
01:06:24,560 --> 01:06:34,640 
 not target width alone that's why it's b and yes it's also true that people make more errors 

498 
01:06:34,640 --> 01:06:41,760 
 under stress what this teaches you is that you can formulate an algorithm that can be an ai 

499 
01:06:41,760 --> 01:06:52,480 
 algorithm or a fits law algorithm but it only focuses on an aspect of the problematic in this case 

500 
01:06:54,240 --> 01:07:1,920 
 the size of things in the interface and how quick and how correctly you can touch it but there are 

501 
01:07:1,920 --> 01:07:12,560 
 always things in the context and in the use and in the situation that people are operating so fits 

502 
01:07:12,560 --> 01:07:22,800 
 law also is under those constraints of in this case stress so fits law under stress works a tiny bit 

503 
01:07:22,800 --> 01:07:32,640 
 different from fits law under a relaxed situation so be aware that algorithms are not the holy 

504 
01:07:32,640 --> 01:07:39,040 
 truth they only separate one single aspect from a far larger problematic 

505 
01:07:43,120 --> 01:07:50,400 
 importance of hei and why you should look into other things than just computing and programming 

506 
01:07:50,400 --> 01:07:58,000 
 here the solution to the fat finger syndrome is solved not through making another interface 

507 
01:07:58,560 --> 01:08:7,040 
 not through coding but through ergonomic design what do i mean i think you have a grandmother 

508 
01:08:7,040 --> 01:08:13,840 
 somewhere who does needlework you know needle and thread but to stick the needle through the cloth 

509 
01:08:13,840 --> 01:08:21,040 
 or the textile she uses a thimble she puts it on her finger and then pushes that needle through the 

510 
01:08:21,040 --> 01:08:30,320 
 cloth now creative designers like in the school of design they will think of hey i have one item 

511 
01:08:30,320 --> 01:08:38,880 
 in one category but it bears some similarity to an item in another category why not make the fingers 

512 
01:08:38,880 --> 01:08:47,920 
 smaller instead of making the target widget wider so they use the concept of a thimble 

513 
01:08:48,640 --> 01:08:56,000 
 adapted to operating an interface and now the whole fat finger syndrome is solved 

514 
01:08:56,560 --> 01:09:4,560 
 through creative design this is why you want to cooperate with other disciplines because no computer 

515 
01:09:4,560 --> 01:09:16,240 
 scientist would ever have thought of using a thimble in order to operate an interface 

